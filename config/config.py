# config/config.py
"""
é¡¹ç›®ç»Ÿä¸€é…ç½®æ–‡ä»¶
é›†ä¸­ç®¡ç†æ‰€æœ‰è¶…å‚æ•°å’Œè·¯å¾„é…ç½®
"""
import os
import json

# ==================== è·¯å¾„é…ç½® ====================
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# æ¨¡å‹è·¯å¾„
MODEL_PATH = os.path.join(PROJECT_ROOT, "models", "qwen_tokenizer_offline", "qwen", "Qwen1___5-1___8B")
OPUS_MT_ZH_EN = os.path.join(PROJECT_ROOT, "models", "opus_mt_zh_en")
OPUS_MT_EN_ZH = os.path.join(PROJECT_ROOT, "models", "opus_mt_en_zh")

# æ•°æ®è·¯å¾„
DATA_ROOT = os.path.join(PROJECT_ROOT, "data")
RAW_DATA_PATH = os.path.join(DATA_ROOT, "raw", "wmt19_zh_en")
TEACHER_LOGITS_DIR = os.path.join(DATA_ROOT, "teacher_logits")
CACHE_DIR = os.path.join(TEACHER_LOGITS_DIR, "cache")

# è¾“å‡ºè·¯å¾„
OUTPUT_ROOT = os.path.join(PROJECT_ROOT, "outputs")
OUTPUT_MODEL_DIR = os.path.join(OUTPUT_ROOT, "models")
OUTPUT_LOGS_DIR = os.path.join(PROJECT_ROOT, "logs")

# åˆ›å»ºå¿…è¦ç›®å½•
for path in [TEACHER_LOGITS_DIR, CACHE_DIR, OUTPUT_MODEL_DIR, OUTPUT_LOGS_DIR]:
    os.makedirs(path, exist_ok=True)

# ==================== æ¨¡å‹é…ç½® ====================
class ModelConfig:
    """å­¦ç”Ÿæ¨¡å‹é…ç½®"""
    # ä» Qwen config.json åŠ¨æ€è¯»å–è¯æ±‡è¡¨å¤§å°
    @staticmethod
    def get_vocab_size():
        config_path = os.path.join(MODEL_PATH, "config.json")
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            return config.get("vocab_size", 151936)
        except Exception as e:
            print(f"âš ï¸ è¯»å– config.json å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼ 151936")
            return 151936
    
    VOCAB_SIZE = get_vocab_size.__func__()  # é™æ€è°ƒç”¨
    MAX_SEQ_LEN = 64

    # TinySeq2SeqTransformer å‚æ•°é…ç½® (é€‚é… encoder-decoder æ¶æ„)

    # æ–¹æ¡ˆ1: æè‡´å‹ç¼© (~10M å‚æ•°)
    TINY_CONFIG = {
        "d_model": 96,
        "nhead": 4,
        "num_encoder_layers": 1,
        "num_decoder_layers": 1,
        "dim_feedforward": 192,
        "dropout": 0.1,
        "share_weights": True
    }

    # æ–¹æ¡ˆ2: å¹³è¡¡æ–¹æ¡ˆ (~20M å‚æ•°) - é»˜è®¤
    BALANCED_CONFIG = {
        "d_model": 128,
        "nhead": 4,
        "num_encoder_layers": 2,
        "num_decoder_layers": 2,
        "dim_feedforward": 256,
        "dropout": 0.1,
        "share_weights": True
    }

    # æ–¹æ¡ˆ3: æ€§èƒ½ä¼˜å…ˆ (~30M å‚æ•°)
    PERFORMANCE_CONFIG = {
        "d_model": 192,
        "nhead": 6,
        "num_encoder_layers": 3,
        "num_decoder_layers": 3,
        "dim_feedforward": 512,
        "dropout": 0.1,
        "share_weights": True
    }

    # å½“å‰ä½¿ç”¨çš„é…ç½®
    CURRENT_CONFIG = BALANCED_CONFIG

# ==================== è®­ç»ƒé…ç½® ====================
class TrainingConfig:
    """è®­ç»ƒè¶…å‚æ•°"""
    EPOCHS = 3
    BATCH_SIZE = 4  # CPU é»˜è®¤å€¼ï¼ŒGPU å»ºè®® 16-32
    GRADIENT_ACCUMULATION_STEPS = 1
    LEARNING_RATE = 3e-4
    TEMPERATURE = 2.0  # KL æ•£åº¦æ¸©åº¦
    PATIENCE = 2  # Early stopping
    
    # AMP é…ç½®
    USE_AMP = True
    USE_COMPILE = False  # torch.compile (éœ€ PyTorch 2.0+)
    
    # æ•°æ®é…ç½®
    MAX_SAMPLES_PER_TASK = None  # None = å…¨é‡
    SHARD_SIZE = 100000  # åˆ†ç‰‡å¤§å°

# ==================== æ•°æ®æ ¼å¼è§„èŒƒ ====================
class DataFormat:
    """ç»Ÿä¸€æ•°æ®æ ¼å¼å®šä¹‰"""
    # æ ‡å‡†é”®å (å¼ºåˆ¶ä½¿ç”¨)
    REQUIRED_KEYS = [
        "id",                    # æ ·æœ¬ID
        "src_text",              # æºè¯­è¨€æ–‡æœ¬
        "tgt_text",              # ç›®æ ‡è¯­è¨€æ–‡æœ¬ (å‚è€ƒç¿»è¯‘)
        "src_input_ids",         # æºè¯­è¨€token IDs
        "src_attention_mask",    # æºè¯­è¨€attention mask
        "tgt_input_ids",         # ç›®æ ‡è¯­è¨€token IDs
        "tgt_attention_mask",    # ç›®æ ‡è¯­è¨€attention mask
        "task_id",               # ä»»åŠ¡ID (0=ä¸­â†’è‹±, 1=è‹±â†’ä¸­)
    ]
    
    # å¯é€‰é”®å
    OPTIONAL_KEYS = [
        "logits",                # Teacher logits (æœ¬åœ°æ¨¡å¼)
        "hyp_text",              # ç¿»è¯‘æ–‡æœ¬ (APIæ¨¡å¼)
        "timestamp",             # ç”Ÿæˆæ—¶é—´æˆ³
    ]
    
    # ä»»åŠ¡æ˜ å°„
    TASK_MAP = {
        "zh_to_en": 0,
        "en_to_zh": 1
    }

# ==================== è®¾å¤‡é…ç½® ====================
class DeviceConfig:
    """è®¡ç®—è®¾å¤‡é…ç½®"""
    import torch
    
    # è‡ªåŠ¨æ£€æµ‹
    CUDA_AVAILABLE = torch.cuda.is_available()
    DEFAULT_DEVICE = "cuda" if CUDA_AVAILABLE else "cpu"
    
    # CPU ä¼˜åŒ–é…ç½®
    CPU_CONFIG = {
        "batch_size": 2,
        "num_workers": 0,
        "int8": True,
        "compile": False
    }
    
    # GPU ä¼˜åŒ–é…ç½®
    GPU_CONFIG = {
        "batch_size": 16,
        "num_workers": 4,
        "int8": False,
        "compile": True
    }

# ==================== æ—¥å¿—é…ç½® ====================
class LogConfig:
    """æ—¥å¿—é…ç½®"""
    LOG_LEVEL = "INFO"  # DEBUG, INFO, WARNING, ERROR
    LOG_FORMAT = '%(asctime)s - %(levelname)s - %(message)s'
    
    # æ—¥å¿—æ–‡ä»¶è·¯å¾„
    GENERATE_LOG = os.path.join(OUTPUT_LOGS_DIR, "generate_logits.log")
    TRAIN_LOG = os.path.join(OUTPUT_LOGS_DIR, "train_distill_amp.log")
    EVALUATE_LOG = os.path.join(OUTPUT_LOGS_DIR, "evaluate_model.log")
    COORDINATE_LOG = os.path.join(OUTPUT_LOGS_DIR, "coordinate_distill.log")

# ==================== è¯„ä¼°é…ç½® ====================
class EvalConfig:
    """è¯„ä¼°é…ç½®"""
    TEST_DATA_PATH = os.path.join(RAW_DATA_PATH, "validation", "validation-00000-of-00001.parquet")
    MAX_EVAL_SAMPLES = 100
    TASKS = ["zh_to_en", "en_to_zh"]
    
    # æ€§èƒ½ç›®æ ‡ (RV1126B)
    TARGET_BLEU = 30.0
    TARGET_LATENCY_MS = 30.0
    TARGET_MEMORY_MB = 512.0

# ==================== è¾…åŠ©å‡½æ•° ====================
def get_config_summary():
    """æ‰“å°é…ç½®æ‘˜è¦"""
    print("=" * 60)
    print("ğŸ“‹ é¡¹ç›®é…ç½®æ‘˜è¦")
    print("=" * 60)
    print(f"ğŸ“¦ è¯æ±‡è¡¨å¤§å°: {ModelConfig.VOCAB_SIZE}")
    print(f"ğŸ“ æœ€å¤§åºåˆ—é•¿åº¦: {ModelConfig.MAX_SEQ_LEN}")
    print(f"ğŸ§  æ¨¡å‹é…ç½®: {ModelConfig.CURRENT_CONFIG}")
    print(f"ğŸ”§ è®­ç»ƒé…ç½®: Epochs={TrainingConfig.EPOCHS}, Batch={TrainingConfig.BATCH_SIZE}")
    print(f"ğŸ’» è®¾å¤‡: {DeviceConfig.DEFAULT_DEVICE}")
    print(f"ğŸ“‚ æ•°æ®è·¯å¾„: {RAW_DATA_PATH}")
    print(f"ğŸ’¾ è¾“å‡ºè·¯å¾„: {OUTPUT_MODEL_DIR}")
    print("=" * 60)

if __name__ == "__main__":
    get_config_summary()
