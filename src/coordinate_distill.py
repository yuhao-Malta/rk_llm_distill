# src/coordinate_distill.py (å¢å¼ºç‰ˆ - è‡ªåŠ¨åˆå¹¶æƒé‡é€‚é…Yuhaoç‰ˆmergeè„šæœ¬)
import os
import argparse
import logging
import subprocess
import torch

# ===========================
# æ—¥å¿—é…ç½®
# ===========================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("logs/coordinate_distill.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)

PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
GENERATE_SCRIPT = os.path.join(PROJECT_ROOT, "scripts", "generate_logits_grok.py")
TRAIN_SCRIPT = os.path.join(PROJECT_ROOT, "src", "train_distill_seq2seq_opt.py")
MERGE_SCRIPT = os.path.join(PROJECT_ROOT, "scripts", "merge_student_checkpoints.py")

OUTPUT_DIR = os.path.join(PROJECT_ROOT, "data", "teacher_logits")
OUTPUT_MODEL_DIR = os.path.join(PROJECT_ROOT, "outputs", "models")
FINAL_MODEL_PATH = os.path.join(OUTPUT_MODEL_DIR, "student_model_final_merged.pth")


def main(args):
    total_shards = (args.max_samples + args.shard_size - 1) // args.shard_size
    logging.info(f"ğŸš€ å¼€å§‹åè°ƒå¼è’¸é¦è®­ç»ƒï¼Œå…± {total_shards} ä¸ªåˆ†ç‰‡")
    logging.info(f"å…¨é‡æ ·æœ¬: {args.max_samples:,}  åˆ†ç‰‡å¤§å°: {args.shard_size:,}")

    # =======================================================
    # Step 1~3: ç”Ÿæˆ Teacher Logits + è®­ç»ƒå­¦ç”Ÿæ¨¡å‹ + æ¸…ç†
    # =======================================================
    for shard_idx in range(total_shards):
        start = shard_idx * args.shard_size
        end = min(start + args.shard_size, args.max_samples)
        logging.info(f"\n{'='*70}\nğŸ§© åˆ†ç‰‡ {shard_idx} [{start:,} - {end:,})\n{'='*70}")

        # Step 1: ç”Ÿæˆ Teacher Logits
        cmd_gen = [
            "python", GENERATE_SCRIPT,
            "--dataset_path", args.dataset_path,
            "--batch_size", str(args.batch_size),
            "--max_seq_len", str(args.max_seq_len),
            "--max_samples", str(args.max_samples),
            "--start_from", str(start),
            "--shard_size", str(args.shard_size),
            "--device", args.device,
            "--shard_idx", str(shard_idx),
        ]
        if args.compile:
            cmd_gen.append("--compile")
        if args.int8:
            cmd_gen.append("--int8")
        if args.simulate_quant_noise:
            cmd_gen.append("--simulate_quant_noise")
            cmd_gen += ["--noise_std", str(args.noise_std)]

        logging.info(f"âš™ï¸ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd_gen)}")
        ret = subprocess.call(cmd_gen)
        if ret != 0:
            logging.error(f"âŒ åˆ†ç‰‡ {shard_idx} Teacher Logits ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡ã€‚")
            continue
        logging.info(f"âœ… åˆ†ç‰‡ {shard_idx} logits ç”Ÿæˆå®Œæˆ")

        # Step 2: è’¸é¦è®­ç»ƒå­¦ç”Ÿæ¨¡å‹
        cmd_train = [
            "python", TRAIN_SCRIPT,
            "--teacher_logits_dir", OUTPUT_DIR,
            "--output_model_dir", OUTPUT_MODEL_DIR,
            "--batch_size", str(args.batch_size),
            "--max_samples_per_task", str(args.shard_size),
            "--device", args.device,
            "--shard_idx", str(shard_idx),
        ]
        if args.compile:
            cmd_train.append("--compile")

        logging.info(f"âš™ï¸ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd_train)}")
        ret = subprocess.call(cmd_train)
        if ret != 0:
            logging.error(f"âŒ åˆ†ç‰‡ {shard_idx} å­¦ç”Ÿæ¨¡å‹è®­ç»ƒå¤±è´¥ï¼Œè·³è¿‡ã€‚")
            continue
        logging.info(f"âœ… åˆ†ç‰‡ {shard_idx} è’¸é¦è®­ç»ƒå®Œæˆ")

        # Step 3: æ¸…ç†ä¸´æ—¶ logits
        for direction in ["zh_to_en", "en_to_zh"]:
            pt_file = os.path.join(OUTPUT_DIR, f"{direction}_shard_{shard_idx}.pt")
            if os.path.exists(pt_file):
                os.remove(pt_file)
                logging.info(f"ğŸ—‘ï¸ åˆ é™¤åˆ†ç‰‡æ–‡ä»¶: {pt_file}")

    # =======================================================
    # Step 4: è‡ªåŠ¨æ‰§è¡Œæ¨¡å‹åˆå¹¶
    # =======================================================
    logging.info("\nğŸ”— æ‰€æœ‰åˆ†ç‰‡è®­ç»ƒå®Œæˆï¼Œå‡†å¤‡åˆå¹¶å­¦ç”Ÿæ¨¡å‹æƒé‡...")
    cmd_merge = [
        "python", MERGE_SCRIPT,
        "--model_dir", OUTPUT_MODEL_DIR,
        "--output_path", FINAL_MODEL_PATH,
        "--device", "cpu",   # å¯æ”¹ä¸ºcudaåˆå¹¶ï¼ˆè‹¥æ˜¾å­˜è¶³å¤Ÿï¼‰
        "--mode", "mean"
    ]

    logging.info(f"âš™ï¸ æ‰§è¡Œæ¨¡å‹åˆå¹¶å‘½ä»¤: {' '.join(cmd_merge)}")
    ret = subprocess.call(cmd_merge)

    if ret == 0:
        logging.info(f"âœ… æ‰€æœ‰åˆ†ç‰‡å·²æˆåŠŸåˆå¹¶ä¸ºæœ€ç»ˆå­¦ç”Ÿæ¨¡å‹ï¼š{FINAL_MODEL_PATH}")
    else:
        logging.error("âŒ æ¨¡å‹åˆå¹¶é˜¶æ®µå‡ºé”™ï¼Œè¯·æ£€æŸ¥ merge_student_checkpoints.py æ—¥å¿—")

    logging.info("\nğŸ‰ å…¨æµç¨‹è’¸é¦ + åˆå¹¶ å®Œæˆï¼")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="åè°ƒåˆ†ç‰‡ç”Ÿæˆ + è®­ç»ƒ + åˆå¹¶ (GPU ä¼˜åŒ–ç‰ˆ)")
    parser.add_argument("--dataset_path", type=str, default="data/raw/wmt19_zh_en", help="WMT19 æ•°æ®è·¯å¾„")
    parser.add_argument("--batch_size", type=int, default=16, help="æ‰¹å¤„ç†å¤§å°")
    parser.add_argument("--max_seq_len", type=int, default=64, help="æœ€å¤§åºåˆ—é•¿åº¦")
    parser.add_argument("--max_samples", type=int, default=26000000, help="å…¨é‡æ ·æœ¬æ•°")
    parser.add_argument("--shard_size", type=int, default=100000, help="æ¯ä¸ªåˆ†ç‰‡çš„æ ·æœ¬æ•°")
    parser.add_argument("--device", type=str, default="cuda" if torch.cuda.is_available() else "cpu", help="è®¡ç®—è®¾å¤‡")
    parser.add_argument("--compile", action="store_true", help="ä½¿ç”¨ torch.compile")
    parser.add_argument("--int8", action="store_true", help="INT8 é‡åŒ–æ•™å¸ˆæ¨¡å‹")
    parser.add_argument("--simulate_quant_noise", action="store_true", help="æ¨¡æ‹Ÿé‡åŒ–å™ªå£°å¢å¼ºå­¦ç”Ÿé²æ£’æ€§")
    parser.add_argument("--noise_std", type=float, default=0.01, help="æ¨¡æ‹Ÿé‡åŒ–å™ªå£°æ ‡å‡†å·®")
    args = parser.parse_args()

    main(args)