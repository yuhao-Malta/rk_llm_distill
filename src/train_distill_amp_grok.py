import sys
import os

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.amp import autocast, GradScaler
from tqdm import tqdm
import logging

from models.tiny_transformer import TinyTransformer
from config.config import (
    ModelConfig, TrainingConfig, DataFormat, LogConfig,
    MODEL_PATH, TEACHER_LOGITS_DIR, OUTPUT_MODEL_DIR, CACHE_DIR
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format=LogConfig.LOG_FORMAT,
    handlers=[
        logging.FileHandler(LogConfig.TRAIN_LOG, encoding='utf-8'),
        logging.StreamHandler()
    ]
)


# ==================== æ•°æ®é›†ç±» ====================
class TranslationDataset(Dataset):
    """
    ç¿»è¯‘æ•°æ®é›† (ç»Ÿä¸€æ ¼å¼)
    ç›´æ¥ä» .pt æ–‡ä»¶åŠ è½½æ•°æ® (å­—æ®µåå·²è§„èŒƒåŒ–)
    """

    def __init__(self, file_path, max_samples=None):
        self.file_path = file_path
        self.max_samples = max_samples

        logging.info(f"ğŸ“¥ åŠ è½½æ•°æ®: {file_path}")
        data = torch.load(file_path)
        self.data = data[:max_samples] if max_samples else data

        # âœ… éªŒè¯æ•°æ®æ ¼å¼
        if len(self.data) > 0:
            sample = self.data[0]
            for key in DataFormat.REQUIRED_KEYS:
                if key not in sample:
                    raise KeyError(f"âŒ æ•°æ®ç¼ºå°‘å¿…éœ€å­—æ®µ: {key}")

        logging.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ (æ ·æœ¬æ•°: {len(self.data)})")

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]


# ==================== collate_fn ====================
def custom_collate_fn(batch, max_seq_len=64, pad_token_id=151643):
    """æ‰¹æ¬¡æ•´ç† (ç»Ÿä¸€å­—æ®µå)"""
    # æ‰€æœ‰å­—æ®µéƒ½ä½¿ç”¨æ ‡å‡†åç§°
    batch_dict = {
        "id": torch.tensor([item["id"] for item in batch], dtype=torch.long),
        "src_input_ids": torch.stack([item["src_input_ids"][:max_seq_len] for item in batch]),
        "src_attention_mask": torch.stack([item["src_attention_mask"][:max_seq_len] for item in batch]),
        "tgt_input_ids": torch.stack([item["tgt_input_ids"][:max_seq_len] for item in batch]),
        "tgt_attention_mask": torch.stack([item["tgt_attention_mask"][:max_seq_len] for item in batch]),
        "task_id": torch.tensor([item["task_id"] for item in batch], dtype=torch.long)
    }

    # å¯é€‰å­—æ®µ
    if "logits" in batch[0] and batch[0]["logits"] is not None:
        batch_dict["logits"] = torch.stack([item["logits"][:max_seq_len, :ModelConfig.VOCAB_SIZE] for item in batch])

    return batch_dict


# -----------------------------
# 3. KL æ•£åº¦æŸå¤±å‡½æ•°
# -----------------------------
def kl_div_loss(student_logits, teacher_logits, temperature=2.0, vocab_size=None):
    """
    çŸ¥è¯†è’¸é¦ KL æ•£åº¦æŸå¤± (æ”¹è¿›ç‰ˆ)

    æ”¹è¿›ç‚¹:
    1. âœ… ä½¿ç”¨ padding è€Œéæˆªæ–­å¤„ç†é•¿åº¦ä¸åŒ¹é…
    2. âœ… åŠ¨æ€è£å‰ªè¯æ±‡è¡¨ç»´åº¦
    3. âœ… å¢åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
    """
    vocab_size = vocab_size or ModelConfig.VOCAB_SIZE
    batch_size = student_logits.size(0)
    seq_len_s = student_logits.size(1)
    seq_len_t = teacher_logits.size(1)
    vocab_s = student_logits.size(2)
    vocab_t = teacher_logits.size(2)

    # 1. å¤„ç†åºåˆ—é•¿åº¦ä¸åŒ¹é… (padding è€Œéæˆªæ–­)
    if seq_len_s != seq_len_t:
        max_len = max(seq_len_s, seq_len_t)
        if seq_len_s < max_len:
            pad = torch.zeros(batch_size, max_len - seq_len_s, vocab_s, device=student_logits.device)
            student_logits = torch.cat([student_logits, pad], dim=1)
        if seq_len_t < max_len:
            pad = torch.zeros(batch_size, max_len - seq_len_t, vocab_t, device=teacher_logits.device)
            teacher_logits = torch.cat([teacher_logits, pad], dim=1)
        logging.debug(f"âš ï¸ åºåˆ—é•¿åº¦ padding: {seq_len_s}, {seq_len_t} â†’ {max_len}")

    # 2. å¤„ç†è¯æ±‡è¡¨å¤§å°ä¸åŒ¹é…
    if vocab_t != vocab_size:
        teacher_logits = teacher_logits[:, :, :vocab_size]
        logging.debug(f"âš ï¸ Teacher è¯æ±‡è¡¨è£å‰ª: {vocab_t} â†’ {vocab_size}")

    # 3. è®¡ç®— KL æ•£åº¦
    s_dist = nn.functional.log_softmax(student_logits / temperature, dim=-1)
    t_dist = nn.functional.softmax(teacher_logits / temperature, dim=-1)

    # æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
    if torch.isnan(s_dist).any() or torch.isnan(t_dist).any():
        logging.warning("âš ï¸ æ£€æµ‹åˆ° NaNï¼Œè·³è¿‡æ­¤ batch")
        return torch.tensor(0.0, device=student_logits.device, requires_grad=True)

    loss = nn.functional.kl_div(s_dist, t_dist, reduction='batchmean') * (temperature ** 2)
    return loss


# ==================== è®­ç»ƒä¸»å‡½æ•° ====================
def train_distill_amp(
        teacher_logits_dir=TEACHER_LOGITS_DIR,
        output_model_dir=OUTPUT_MODEL_DIR,
        epochs=None,
        batch_size=None,
        gradient_accumulation_steps=None,
        learning_rate=None,
        max_samples_per_task=None,
        device=None,
        max_seq_len=None,
        compile=None,
        shard_idx=0,
        patience=None
):
    """
    å¤šä»»åŠ¡è’¸é¦è®­ç»ƒ (AMP + ç»Ÿä¸€æ ¼å¼)

    æ”¹è¿›ç‚¹:
    1. âœ… ç»Ÿä¸€æ•°æ®å­—æ®µå
    2. âœ… æ”¹è¿› KL æ•£åº¦è®¡ç®—
    3. âœ… å¢å¼ºé”™è¯¯å¤„ç†
    4. âœ… è‡ªåŠ¨ä»é…ç½®æ–‡ä»¶è¯»å–å‚æ•°
    """
    # ä»é…ç½®æ–‡ä»¶è·å–é»˜è®¤å€¼
    epochs = epochs or TrainingConfig.EPOCHS
    batch_size = batch_size or TrainingConfig.BATCH_SIZE
    gradient_accumulation_steps = gradient_accumulation_steps or TrainingConfig.GRADIENT_ACCUMULATION_STEPS
    learning_rate = learning_rate or TrainingConfig.LEARNING_RATE
    patience = patience or TrainingConfig.PATIENCE
    max_seq_len = max_seq_len or ModelConfig.MAX_SEQ_LEN

    # è®¾å¤‡
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    elif isinstance(device, str):
        device = torch.device(device)

    logging.info("=" * 60)
    logging.info("ğŸš€ å¼€å§‹å¤šä»»åŠ¡è’¸é¦è®­ç»ƒ")
    logging.info("=" * 60)
    logging.info(f"ğŸ“¦ è®¾å¤‡: {device}")
    logging.info(f"ğŸ“Š è®­ç»ƒé…ç½®: Epochs={epochs}, Batch={batch_size}, LR={learning_rate}")
    logging.info(f"ğŸ”§ AMP: {TrainingConfig.USE_AMP}, Compile: {compile or TrainingConfig.USE_COMPILE}")

    # 1. åˆå§‹åŒ–å­¦ç”Ÿæ¨¡å‹
    try:
        model = TinyTransformer(
            vocab_size=ModelConfig.VOCAB_SIZE,
            max_seq_len=max_seq_len,
            **ModelConfig.CURRENT_CONFIG
        ).to(device)

        if compile and device.type == "cuda":
            model = torch.compile(model)

        model.num_parameters(verbose=True)
    except Exception as e:
        logging.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        raise

    # 2. åŠ è½½æ•°æ®é›†
    zh_to_en_path = os.path.join(teacher_logits_dir, f"zh_to_en_shard_{shard_idx}.pt")
    en_to_zh_path = os.path.join(teacher_logits_dir, f"en_to_zh_shard_{shard_idx}.pt")

    try:
        dataset_zh_en = TranslationDataset(zh_to_en_path, max_samples=max_samples_per_task)
        dataset_en_zh = TranslationDataset(en_to_zh_path, max_samples=max_samples_per_task)
    except Exception as e:
        logging.error(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        raise

    # 3. DataLoader
    loader_zh_en = DataLoader(
        dataset_zh_en,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0,
        pin_memory=(device.type == "cuda"),
        collate_fn=lambda b: custom_collate_fn(b, max_seq_len=max_seq_len, pad_token_id=model.tokenizer.pad_token_id)
    )
    loader_en_zh = DataLoader(
        dataset_en_zh,
        batch_size=batch_size,
        shuffle=True,
        num_workers=0,
        pin_memory=(device.type == "cuda"),
        collate_fn=lambda b: custom_collate_fn(b, max_seq_len=max_seq_len, pad_token_id=model.tokenizer.pad_token_id)
    )

    # 4. ä¼˜åŒ–å™¨ + AMP
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)
    scaler = GradScaler("cuda", enabled=(device.type == "cuda" and TrainingConfig.USE_AMP))

    # 5. è®­ç»ƒå¾ªç¯
    model.train()
    best_loss = float('inf')
    epochs_no_improve = 0

    for epoch in range(epochs):
        logging.info(f"\n{'=' * 60}")
        logging.info(f"ğŸ“… Epoch {epoch + 1}/{epochs}")
        logging.info(f"{'=' * 60}")

        total_loss = 0.0
        total_batches = 0

        # ä¸­â†’è‹±è®­ç»ƒ
        logging.info("ğŸ§  è®­ç»ƒä¸­â†’è‹±ä»»åŠ¡...")
        pbar = tqdm(loader_zh_en, desc="ä¸­â†’è‹±")
        for step, batch in enumerate(pbar):
            try:
                # æ•°æ®è¿ç§»åˆ°è®¾å¤‡
                src_input_ids = batch["src_input_ids"].to(device)
                src_attention_mask = batch["src_attention_mask"].to(device)
                task_ids = batch["task_id"].to(device)
                teacher_logits = batch["logits"].to(device) if "logits" in batch else None

                # å‰å‘ä¼ æ’­
                with autocast(device_type="cuda" if device.type == "cuda" else "cpu", enabled=TrainingConfig.USE_AMP):
                    outputs = model(
                        input_ids=src_input_ids,
                        attention_mask=src_attention_mask,
                        task_id=task_ids
                    )
                    student_logits = outputs["logits"]

                    # è®¡ç®—æŸå¤±
                    if teacher_logits is not None:
                        loss = kl_div_loss(student_logits, teacher_logits,
                                           temperature=TrainingConfig.TEMPERATURE,
                                           vocab_size=ModelConfig.VOCAB_SIZE)
                    else:
                        logging.warning("âš ï¸ æ—  teacher_logitsï¼Œè·³è¿‡")
                        continue

                    loss = loss / gradient_accumulation_steps

                # åå‘ä¼ æ’­
                scaler.scale(loss).backward()

                # æ¢¯åº¦ç´¯ç§¯
                if (step + 1) % gradient_accumulation_steps == 0:
                    scaler.step(optimizer)
                    scaler.update()
                    optimizer.zero_grad()

                total_loss += loss.item() * gradient_accumulation_steps
                total_batches += 1
                pbar.set_postfix({"loss": f"{loss.item() * gradient_accumulation_steps:.4f}"})

            except Exception as e:
                logging.error(f"âŒ ä¸­â†’è‹±è®­ç»ƒå¤±è´¥ (step {step}): {e}")
                continue

        # è‹±â†’ä¸­è®­ç»ƒ
        logging.info("ğŸ§  è®­ç»ƒè‹±â†’ä¸­ä»»åŠ¡...")
        pbar = tqdm(loader_en_zh, desc="è‹±â†’ä¸­")
        for step, batch in enumerate(pbar):
            try:
                src_input_ids = batch["src_input_ids"].to(device)
                src_attention_mask = batch["src_attention_mask"].to(device)
                task_ids = batch["task_id"].to(device)
                teacher_logits = batch["logits"].to(device) if "logits" in batch else None

                with autocast(device_type="cuda" if device.type == "cuda" else "cpu", enabled=TrainingConfig.USE_AMP):
                    outputs = model(
                        input_ids=src_input_ids,
                        attention_mask=src_attention_mask,
                        task_id=task_ids
                    )
                    student_logits = outputs["logits"]

                    if teacher_logits is not None:
                        loss = kl_div_loss(student_logits, teacher_logits,
                                           temperature=TrainingConfig.TEMPERATURE,
                                           vocab_size=ModelConfig.VOCAB_SIZE)
                    else:
                        continue

                    loss = loss / gradient_accumulation_steps

                scaler.scale(loss).backward()

                if (step + 1) % gradient_accumulation_steps == 0:
                    scaler.step(optimizer)
                    scaler.update()
                    optimizer.zero_grad()

                total_loss += loss.item() * gradient_accumulation_steps
                total_batches += 1
                pbar.set_postfix({"loss": f"{loss.item() * gradient_accumulation_steps:.4f}"})

            except Exception as e:
                logging.error(f"âŒ è‹±â†’ä¸­è®­ç»ƒå¤±è´¥ (step {step}): {e}")
                continue

        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = total_loss / total_batches if total_batches > 0 else float('inf')
        logging.info(f"âœ… Epoch {epoch + 1} å®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.4f}")

        # Early stopping
        if avg_loss < best_loss:
            best_loss = avg_loss
            epochs_no_improve = 0
            best_model_path = os.path.join(output_model_dir, f"student_model_amp_shard_{shard_idx}_best.pth")
            torch.save(model.state_dict(), best_model_path)
            logging.info(f"ğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_model_path}")
        else:
            epochs_no_improve += 1
            if epochs_no_improve >= patience:
                logging.info(f"ğŸ›‘ Early stopping è§¦å‘ (Epoch {epoch + 1})")
                break

        # ä¿å­˜æ¯è½®æ¨¡å‹
        model_path = os.path.join(output_model_dir, f"student_model_amp_shard_{shard_idx}_epoch_{epoch + 1}.pth")
        torch.save(model.state_dict(), model_path)
        logging.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")

        # âœ… ä»…ä¿ç•™æœ€ä½³æ¨¡å‹ï¼Œç«‹å³åˆ é™¤å½“å‰epochæ–‡ä»¶
        if avg_loss < best_loss:
            best_loss = avg_loss
            best_model_path = os.path.join(output_model_dir, f"student_model_amp_shard_{shard_idx}_best.pth")
            torch.save(model.state_dict(), best_model_path)
            logging.info(f"ğŸ† æ–°æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_model_path}")
        else:
            # åˆ é™¤å½“å‰epochæ–‡ä»¶ï¼ˆéæœ€ä½³ï¼‰
            os.remove(model_path)
            logging.info(f"ğŸ—‘ï¸ åˆ é™¤éæœ€ä½³æ¨¡å‹: {model_path}")

    logging.info("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
    return best_model_path if best_loss < float('inf') else model_path


# ==================== ä¸»ç¨‹åº ====================
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="å¤šä»»åŠ¡è’¸é¦è®­ç»ƒ (ä¼˜åŒ–ç‰ˆ)")
    parser.add_argument("--teacher_logits_dir", type=str, default=TEACHER_LOGITS_DIR)
    parser.add_argument("--output_model_dir", type=str, default=OUTPUT_MODEL_DIR)
    parser.add_argument("--epochs", type=int, default=None)
    parser.add_argument("--batch_size", type=int, default=None)
    parser.add_argument("--gradient_accumulation_steps", type=int, default=None)
    parser.add_argument("--learning_rate", type=float, default=None)
    parser.add_argument("--max_samples_per_task", type=int, default=None)
    parser.add_argument("--device", type=str, default=None)
    parser.add_argument("--max_seq_len", type=int, default=None)
    parser.add_argument("--compile", action="store_true")
    parser.add_argument("--shard_idx", type=int, default=0)
    parser.add_argument("--patience", type=int, default=None)
    args = parser.parse_args()

    train_distill_amp(
        teacher_logits_dir=args.teacher_logits_dir,
        output_model_dir=args.output_model_dir,
        epochs=args.epochs,
        batch_size=args.batch_size,
        gradient_accumulation_steps=args.gradient_accumulation_steps,
        learning_rate=args.learning_rate,
        max_samples_per_task=args.max_samples_per_task,
        device=args.device,
        max_seq_len=args.max_seq_len,
        compile=args.compile,
        shard_idx=args.shard_idx,
        patience=args.patience
    )