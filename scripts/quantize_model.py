#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ¨¡å‹é‡åŒ–è„šæœ¬ (å¢å¼ºç‰ˆ)
====================================
æ”¯æŒå‘½ä»¤è¡Œå‚æ•° + è¾“å‡ºå¯¹æ¯”ä¿¡æ¯æŠ¥å‘Š

ç¤ºä¾‹ï¼š
    python scripts/quantize_model.py \
        --input_model outputs/models/student_model_final_merged.pth \
        --output_model outputs/models/student_model_int8.pth
"""

import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import argparse
import torch
import torch.quantization
from models.tiny_transformer import TinyTransformer
import logging
from datetime import datetime

# =====================
# æ—¥å¿—é…ç½®
# =====================
os.makedirs("logs", exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("logs/quantize_model.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# =====================
# å‚æ•°è§£æ
# =====================
parser = argparse.ArgumentParser(description="åŠ¨æ€é‡åŒ– Transformer å­¦ç”Ÿæ¨¡å‹")
parser.add_argument("--input_model", type=str, default="outputs/models/student_model_final_merged.pth",
                    help="å¾…é‡åŒ–çš„æ¨¡å‹è·¯å¾„")
parser.add_argument("--output_model", type=str, default="outputs/models/student_model_int8.pth",
                    help="ä¿å­˜é‡åŒ–æ¨¡å‹çš„è¾“å‡ºè·¯å¾„")
parser.add_argument("--report_path", type=str, default="logs/quantization_report.txt",
                    help="é‡åŒ–æŠ¥å‘Šè¾“å‡ºè·¯å¾„")
args = parser.parse_args()

# =====================
# åŠ è½½æ¨¡å‹
# =====================
try:
    model = TinyTransformer(
        vocab_size=151936,
        max_seq_len=64,
        d_model=128,
        nhead=4,
        num_layers=2,
        share_weights=True
    )

    logging.info(f"ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹: {args.input_model}")
    state_dict = torch.load(args.input_model, map_location="cpu")
    model.load_state_dict(state_dict, strict=False)
    logging.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {args.input_model}")

except Exception as e:
    logging.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    raise

# =====================
# é‡åŒ–
# =====================
try:
    model.eval()
    if hasattr(torch.quantization, 'float_qparams_weight_only_qconfig'):
        logging.info("âœ… ä½¿ç”¨ float_qparams_weight_only_qconfig é‡åŒ– nn.Embedding ä¸ nn.Linear")
        quantized_model = torch.quantization.quantize_dynamic(
            model,
            qconfig_spec={
                torch.nn.Linear: torch.quantization.default_dynamic_qconfig,
                torch.nn.Embedding: torch.quantization.float_qparams_weight_only_qconfig
            },
            dtype=torch.qint8
        )
    else:
        logging.warning("âš ï¸ float_qparams_weight_only_qconfig ä¸å¯ç”¨ï¼Œä»…é‡åŒ– Linear å±‚")
        quantized_model = torch.quantization.quantize_dynamic(
            model, {torch.nn.Linear}, dtype=torch.qint8
        )
    logging.info("âœ… æ¨¡å‹é‡åŒ–æˆåŠŸ")
except Exception as e:
    logging.error(f"âŒ æ¨¡å‹é‡åŒ–å¤±è´¥: {e}")
    raise

# =====================
# ä¿å­˜å®Œæ•´é‡åŒ–æ¨¡å‹
# =====================
try:
    os.makedirs(os.path.dirname(args.output_model), exist_ok=True)
    torch.save(quantized_model, args.output_model)   # âœ… ä¿å­˜å®Œæ•´æ¨¡å‹å¯¹è±¡
    logging.info(f"âœ… é‡åŒ–æ¨¡å‹å·²å®Œæ•´ä¿å­˜è‡³: {args.output_model}")
except Exception as e:
    logging.error(f"âŒ ä¿å­˜é‡åŒ–æ¨¡å‹å¤±è´¥: {e}")
    raise

# =====================
# ğŸ“Š ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
# =====================
try:
    def sizeof(file_path):
        return os.path.getsize(file_path) / (1024 * 1024) if os.path.exists(file_path) else 0

    orig_size = sizeof(args.input_model)
    quant_size = sizeof(args.output_model)
    compression_ratio = orig_size / quant_size if quant_size > 0 else 0

    orig_param_count = len(state_dict.keys())
    quant_param_count = len(quantized_model.state_dict().keys())

    report_lines = [
        "=" * 70,
        f"ğŸ§® æ¨¡å‹é‡åŒ–å¯¹æ¯”æŠ¥å‘Š",
        "=" * 70,
        f"ğŸ•’ æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "",
        f"ğŸ“¥ åŸå§‹æ¨¡å‹: {args.input_model}",
        f"ğŸ“¦ é‡åŒ–æ¨¡å‹: {args.output_model}",
        "",
        f"ğŸ”¢ å‚æ•°æ•°é‡: {orig_param_count:,} â†’ {quant_param_count:,}",
        f"ğŸ’¾ æ¨¡å‹ä½“ç§¯: {orig_size:.2f} MB â†’ {quant_size:.2f} MB",
        f"ğŸ“‰ å‹ç¼©æ¯”: {compression_ratio:.2f}x",
        "",
        "âœ… é‡åŒ–ç±»å‹: åŠ¨æ€é‡åŒ– (Dynamic Quantization)",
        "âœ… æ¶‰åŠå±‚: nn.Linear + nn.Embedding (å¦‚å¯ç”¨)",
        "=" * 70
    ]

    os.makedirs(os.path.dirname(args.report_path), exist_ok=True)
    with open(args.report_path, "w", encoding="utf-8") as f:
        f.write("\n".join(report_lines))

    # åŒæ­¥è¾“å‡ºåˆ°æ—¥å¿—
    logging.info("\n" + "\n".join(report_lines))
    logging.info(f"ğŸ“„ é‡åŒ–æŠ¥å‘Šå·²ä¿å­˜è‡³: {args.report_path}")

except Exception as e:
    logging.error(f"âŒ ç”Ÿæˆé‡åŒ–æŠ¥å‘Šå¤±è´¥: {e}")
    raise